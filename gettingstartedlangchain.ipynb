{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de862e3e-001e-4f77-8df6-c1d82f531ca2",
   "metadata": {},
   "source": [
    "# Getting started with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3caf3fa-78ef-46b5-a150-20a080604abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae95606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the environment variables\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a95342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL STEP] - Reload the environment variables\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking And Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad5a07-8b36-4b3d-9433-a37dd2023855",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create model object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939cf7dc-e46c-4f4a-a677-33aa2ad3c859",
   "metadata": {},
   "source": [
    "#### With OpenAI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4057757c-44b2-49b8-ae30-065ea40c9f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000029F2F3325A0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000029F32FB23C0> root_client=<openai.OpenAI object at 0x0000029F2D55EA50> root_async_client=<openai.AsyncOpenAI object at 0x0000029F2F32CDD0> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "# Load default LLM model from OpenAI Chat models\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")  # 'gpt-3.5-turbo' is the default model used if no model parameter is provided\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35ca146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Langchain wrapper built on Open AI chat completion API, we just need to use \"invoke\" method to pass the user query\n",
    "result=llm.invoke(\"What is Agentic AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41d6b3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Agentic AI** refers to artificial intelligence systems designed to act as autonomous agents capable of making independent decisions and taking actions to achieve specific goals within their environments. The term \"agentic\" emphasizes the AI's ability to perceive its surroundings, process information, and execute tasks without continuous human intervention. These AI agents often incorporate elements of autonomy, adaptability, and goal-oriented behavior, making them suitable for a wide range of applications.\n",
       "\n",
       "### Key Characteristics of Agentic AI\n",
       "\n",
       "1. **Autonomy**: Agentic AI systems operate independently, making decisions based on their programming and the data they gather from their environment.\n",
       "2. **Perception**: They can sense and interpret data from their surroundings using various sensors or data inputs.\n",
       "3. **Decision-Making**: These agents employ algorithms to analyze information and determine the most appropriate actions to take toward achieving their objectives.\n",
       "4. **Adaptability**: Agentic AI can learn from experiences, allowing them to improve their performance over time through methods such as machine learning.\n",
       "5. **Goal-Oriented Behavior**: They are designed with specific goals or objectives that guide their actions and decision-making processes.\n",
       "\n",
       "### Applications of Agentic AI\n",
       "\n",
       "1. **Autonomous Vehicles**: Self-driving cars use agentic AI to navigate roads, interpret traffic signals, and respond to dynamic driving conditions without human input.\n",
       "2. **Robotics**: Industrial robots, service robots, and drones utilize agentic AI to perform tasks ranging from manufacturing to delivery services autonomously.\n",
       "3. **Virtual Assistants**: AI-powered assistants like Siri, Alexa, and Google Assistant act as agentic AI by performing tasks, managing schedules, and interacting with other smart devices based on user commands.\n",
       "4. **Gaming**: Intelligent non-player characters (NPCs) in video games exhibit agentic behavior to enhance the gaming experience by responding dynamically to player actions.\n",
       "5. **Healthcare**: AI agents can monitor patient data, manage treatment plans, and even assist in surgeries by making real-time decisions based on patient needs.\n",
       "\n",
       "### Technical Foundations\n",
       "\n",
       "Agentic AI typically leverages several branches of artificial intelligence, including:\n",
       "\n",
       "- **Machine Learning (ML)**: Enables AI agents to learn from data and improve their performance over time.\n",
       "- **Reinforcement Learning (RL)**: Allows agents to learn optimal actions through trial and error by receiving rewards or penalties.\n",
       "- **Natural Language Processing (NLP)**: Facilitates understanding and generation of human language, crucial for interactive agents.\n",
       "- **Computer Vision**: Provides the ability to interpret and understand visual information from the environment.\n",
       "\n",
       "### Ethical and Safety Considerations\n",
       "\n",
       "As Agentic AI systems become more autonomous and integrated into critical aspects of society, several ethical and safety concerns arise:\n",
       "\n",
       "- **Accountability**: Determining responsibility for decisions made by autonomous agents, especially in cases of malfunction or unintended consequences.\n",
       "- **Bias and Fairness**: Ensuring that AI agents make decisions free from biases present in their training data or algorithms.\n",
       "- **Privacy**: Protecting sensitive data that AI agents may collect and process during their operations.\n",
       "- **Security**: Safeguarding AI systems against malicious attacks that could compromise their autonomy and functionality.\n",
       "- **Transparency**: Making the decision-making processes of AI agents understandable to users and stakeholders.\n",
       "\n",
       "### Future Directions\n",
       "\n",
       "The development of Agentic AI continues to advance, with ongoing research focused on enhancing autonomy, improving adaptability, and ensuring ethical alignment with human values. Future advancements may lead to more sophisticated AI agents capable of complex tasks, deeper integration into various industries, and more seamless interaction with humans and other systems.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "Agentic AI represents a significant evolution in artificial intelligence, emphasizing autonomy and purposeful action. By designing AI systems that can independently navigate, learn, and act to achieve defined objectives, Agentic AI holds the potential to transform numerous sectors, driving efficiency, innovation, and new capabilities. However, as these systems become more prevalent, it is crucial to address the accompanying ethical and safety challenges to ensure their responsible and beneficial integration into society."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the output generated by the model\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff100c-2ba3-4757-b073-3050cd125e20",
   "metadata": {},
   "source": [
    "#### With Groq models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8357dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "result = model.invoke(\"What is the difference between AI Agent and Agentic AI. Answer in 100 words. Return final answer in Markdown format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb23240b-5eed-400c-818f-370bc3bffe01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "<think>\n",
       "Okay, so the user wants to know the difference between an AI Agent and Agentic AI. Let me start by recalling what each term usually means. \n",
       "\n",
       "First, an AI Agent. From what I remember, an AI Agent is a system that can perceive its environment through sensors and acts upon that environment through effectors. It's an autonomous entity that makes decisions based on its goals. Like a chatbot or a recommendation system, right? They follow predefined tasks and rules. They're designed to perform specific functions, maybe like scheduling emails or playing a game.\n",
       "\n",
       "Now, Agentic AI. Hmm, I'm not as familiar with that term. Maybe it's a more recent concept. The term \"agentic\" relates to agency, which implies the capacity to act independently. Could Agentic AI refer to systems that have more autonomy and initiative? Maybe they can set their own goals or adapt their behavior in complex ways beyond just following a set of instructions. I've heard of the term in discussions about advanced AI systems that can take initiative without explicit programming for every scenario.\n",
       "\n",
       "Wait, maybe there's some overlap here. Both terms involve AI acting on its own, but the key difference might be in the level of autonomy and adaptability. AI Agents are probably more restricted to predefined tasks, while Agentic AI has higher autonomy, perhaps even self-directed goals. But I need to verify that. \n",
       "\n",
       "Looking up some references in my mind, I recall that Agentic AI might be a term used in contexts where the AI has the ability to plan and execute tasks over time, possibly in dynamic environments. It might involve learning and adapting strategies without human intervention. In contrast, standard AI Agents might have a fixed set of actions and decision-making processes.\n",
       "\n",
       "Another angle: the term \"Agentic\" could imply that the AI has a sense of agency, meaning it can make decisions that influence the environment in pursuit of objectives, maybe even with some form of self-awareness or intent. But that might be stretching it. Alternatively, Agentic AI could be a type of AI Agent with enhanced capabilities for autonomy and adaptability.\n",
       "\n",
       "So, to differentiate: AI Agents are the broader category of systems that perform tasks autonomously, while Agentic AI specifically denotes a subset with higher levels of autonomy, initiative, and possibly self-directed goals. Or maybe it's the other way around? Wait, maybe the key is in the terminology. The user is asking for the difference, so I need to be precise.\n",
       "\n",
       "Alternatively, sometimes \"Agentic AI\" might be a specific framework or approach. Wait, perhaps \"Agentic AI\" refers to systems that can act as agents in a multi-agent system, coordinating with other agents. But that might not be the distinction here.\n",
       "\n",
       "Wait, maybe there's a recent trend or paper that uses \"Agentic AI\" to describe a new paradigm. For example, in the context of alignment or safety, Agentic AI could refer to systems that have their own agency, which might pose challenges if their goals aren't aligned with human interests. So Agentic AI might emphasize the aspect of having independent agency, possibly leading to unintended consequences, whereas AI Agents are more controlled.\n",
       "\n",
       "Putting this together: AI Agents are general purpose autonomous systems designed for specific tasks. Agentic AI emphasizes autonomous decision-making, possibly with self-driven objectives, leading to behaviors that might be more unpredictable or proactive. \n",
       "\n",
       "Wait, the user wants a 100-word answer. Let me structure it concisely. Start by defining each term, then contrast their key aspects like autonomy, goal-setting, and scope. Maybe AI Agents are task-specific with predefined goals, while Agentic AI has broader autonomy, self-directed goals, and can operate more independently in complex environments. Make sure to highlight the main differences in a clear, concise way without jargon.\n",
       "</think>\n",
       "\n",
       "AI Agents are autonomous systems designed to perform specific tasks by perceiving environments and executing actions. They follow predefined goals, rules, and workflows, often within narrow domains like chatbots or recommendation systems.  \n",
       "\n",
       "Agentic AI, however, emphasizes **autonomy and initiative**, where systems can dynamically set or adjust their own objectives, learn, and adapt strategies in complex, unstructured environments. Agentic AI prioritizes self-directed decision-making, often with broader problem-solving capabilities beyond fixed tasks.  \n",
       "\n",
       "Key differences:  \n",
       "- **Goals**: AI Agents follow *predefined objectives*; Agentic AI may *self-define or evolve goals*.  \n",
       "- **Autonomy**: AI Agents act within strict boundaries; Agentic AI operates with *greater independence*.  \n",
       "- **Complexity**: AI Agents handle specific tasks; Agentic AI tackles adaptive, multi-step problems.  \n",
       "\n",
       "Agentic AI represents a more advanced, self-driven form of AI, while AI Agents are task-oriented tools."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda82a55-6ffc-4867-b532-0a1ee0f8814c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c8d29d3-f6cc-43b7-9335-16ed9fba38f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Using Prompt Templates and Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88e170b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['business_rules', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['business_rules'], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question. Additionally, follow the business rules: {business_rules}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create prompt using Langchain Chat prompt template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question. Additionally, follow the business rules: {business_rules}\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d40b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['business_rules', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['business_rules'], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question. Additionally, follow the business rules: {business_rules}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000029F34063EF0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000029F34068B60>, model_name='qwen-qwq-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chaining - Langchain allows combining multiple actions using chain \n",
    "chain = prompt | model  # 👈 prompt is passed to the LLM model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a293571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "<think>\n",
       "Okay, the user is asking about Langsmith. I need to explain what it is and its key features. Let me start by recalling what I know. Langsmith is a tool related to language models, probably from LangChain. It's used for monitoring and improving LLM workflows. \n",
       "\n",
       "First, I should define Langsmith clearly. Mention that it's a platform for tracking and optimizing LLM applications. Then list its main features. I remember it has a UI for visualization, maybe something about tracing runs. \n",
       "\n",
       "I need to cover key features like run tracing, which allows tracking of each step in a workflow. Then, dataset management, so users can store and organize their data. Evaluation and feedback are important for improving models. \n",
       "\n",
       "Also, there's a collaboration aspect, letting teams share insights. Integration with LangChain is key, so it's part of that ecosystem. Use cases might include MLOps for LLMs, debugging, and model optimization. \n",
       "\n",
       "I should also mention the benefits: better insights, collaboration, and efficiency. Make sure to structure it in markdown with headers and bullet points. Check for any business rules: output must be in markdown, so I'll use the appropriate syntax. \n",
       "\n",
       "Wait, the user might be looking for practical info like how it helps in development or deployment. Make sure to highlight those points. Also, clarify that it's developed by LangChain, so the user knows the origin. \n",
       "\n",
       "Avoid any technical jargon that's too dense. Keep it clear and concise. Alright, putting it all together now.\n",
       "</think>\n",
       "\n",
       "```markdown\n",
       "# Langsmith Overview\n",
       "\n",
       "Langsmith is a purpose-built platform for **monitoring, analyzing, and optimizing Large Language Model (LLM)** workflows. It is part of the **LangChain ecosystem** and provides tools to track and improve the performance of LLM applications. Below is a structured overview of its key features, use cases, and benefits.\n",
       "\n",
       "---\n",
       "\n",
       "## Key Features\n",
       "\n",
       "### 1. **Run Tracing and Visualization**\n",
       "   - **Workflow Tracking**: Logs and visualizes every step of an LLM workflow, including prompts, responses, and intermediate steps.\n",
       "   - **Traces Dashboard**: Provides a UI to inspect runs, compare results, and identify bottlenecks in real-time.\n",
       "\n",
       "### 2. **Dataset Management**\n",
       "   - Stores and organizes input/output pairs (datasets) for LLM applications.\n",
       "   - Enables versioning of datasets to track changes over time.\n",
       "\n",
       "### 3. **Evaluation & Feedback**\n",
       "   - Built-in tools for **automated and manual evaluation** of model outputs (e.g., accuracy, relevance, safety).\n",
       "   - Supports **human-in-the-loop feedback** to refine models and workflows.\n",
       "\n",
       "### 4. **Collaboration & Sharing**\n",
       "   - Shares insights and datasets across teams.\n",
       "   - Exportable reports for audits or documentation.\n",
       "\n",
       "### 5. **Integration with LangChain**\n",
       "   - Seamlessly integrates with LangChain libraries (Python/JavaScript) to log and analyze workflows.\n",
       "   - Works with any LLM (e.g., OpenAI, Anthropic, custom models).\n",
       "\n",
       "---\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "- **MLOps for LLMs**: Track performance and debug issues in production.\n",
       "- **Model Optimization**: Identify underperforming parts of workflows.\n",
       "- **QA Testing**: Validate outputs against predefined criteria.\n",
       "- **Iterative Development**: Refine prompts, data, and workflows based on feedback.\n",
       "- **Compliance & Auditing**: Maintain records of model behavior for regulatory purposes.\n",
       "\n",
       "---\n",
       "\n",
       "## Benefits\n",
       "\n",
       "- **Transparency**: Understand \"black-box\" LLM behavior through detailed traces.\n",
       "- **Efficiency**: Streamline development and deployment cycles.\n",
       "- **Scalability**: Supports large-scale workflows and datasets.\n",
       "- **Collaboration**: Centralized workspace for teams.\n",
       "\n",
       "---\n",
       "\n",
       "## Getting Started\n",
       "\n",
       "- **Installation**: Use `pip install langchain` (includes LangSmith SDK).\n",
       "- **Integration**: Add a few lines of code to log runs in LangChain workflows.\n",
       "- **Access**: The UI is hosted on [app.langchain.com](https://app.langchain.com).\n",
       "\n",
       "---\n",
       "\n",
       "Langsmith is ideal for developers, data scientists, and teams building LLM applications, enabling them to iteratively improve model performance and maintain operational rigor.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use invoke method to pass the query and input variables\n",
    "response=chain.invoke({\"business_rules\":\"MUST generate output in Markdown format\", \"input\":\"Can you tell me something about Langsmith\"})\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd6073-4671-483e-a3bd-c5758dbb4d96",
   "metadata": {},
   "source": [
    "## Generating structured output using LangChain output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a70c67-e9e8-466a-8d06-04d960e1909d",
   "metadata": {},
   "source": [
    "👉  **StrOutputParser** in LangChain is the most fundamental output parser, designed to transform the raw output from a Language Model (LLM) or ChatModel into a plain string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6694a12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "<think>\n",
       "Okay, I need to explain what Langsmith is. Let me start by recalling what I know. Langsmith is a tool related to LangChain, right? I think LangChain is a framework for building applications with language models, so Langsmith might be part of that ecosystem. \n",
       "\n",
       "The user asked for an overview of Langsmith. I should mention that it's a UI tool for LangChain, maybe for monitoring and managing workflows. I remember that LangChain has components like Chains, Agents, and Models. Langsmith probably helps track these components' performance. \n",
       "\n",
       "Wait, the business rules require me to be concise, use clear sections, and include a summary. Let me structure the answer into sections like Overview, Key Features, Use Cases, and a Summary. \n",
       "\n",
       "First, the overview: Langsmith is a UI/Analytics tool built by LangChain to help developers monitor and optimize their LLM applications. It's part of LangChain's ecosystem. \n",
       "\n",
       "Key Features: Maybe visualization of workflows, performance tracking, version control for experiments, error detection, and integration with LangChain. I should list these points clearly. \n",
       "\n",
       "Use Cases: Debugging issues, comparing model versions, tracking cost, and team collaboration. These are common scenarios where such a tool would be useful. \n",
       "\n",
       "I should make sure not to use markdown, just plain text. Also, need to keep each section brief. Let me check if I missed anything. Oh, the user might be looking to integrate it into their projects, so mentioning how it's used with LangChain is important. \n",
       "\n",
       "Wait, in the business rules, the user wants me to follow specific rules like being concise, using clear sections, and avoiding unnecessary details. So I need to keep each section to a few sentences. \n",
       "\n",
       "I should also ensure that the summary ties everything together, emphasizing how Langsmith helps developers. Avoid technical jargon where possible, but since the user is asking about Langsmith, they might be a developer or technical user. \n",
       "\n",
       "Let me put it all together now. Start with the overview, then key features in bullet points, then use cases, and a summary. Make sure each section is a separate paragraph without using markdown. Alright, that should cover it.\n",
       "</think>\n",
       "\n",
       "**Langsmith Overview**  \n",
       "Langsmith is a user interface (UI) and analytics tool developed by LangChain, designed to help developers monitor, debug, and optimize their large language model (LLM) workflows. It serves as a companion to LangChain, enabling users to track and analyze the performance of complex LLM-based applications.\n",
       "\n",
       "---\n",
       "\n",
       "**Key Features**  \n",
       "1. **Workflow Visualization**: Provides a visual interface to map and track LangChain components (e.g., Chains, Agents, Models) in real time.  \n",
       "2. **Performance Monitoring**: Offers metrics like response times, error rates, and throughput to identify bottlenecks.  \n",
       "3. **Experiment Tracking**: Lets users version control experiments, compare model outputs, and log parameters for reproducibility.  \n",
       "4. **Error Debugging**: Highlights failures in workflows (e.g., input misinterpretation, invalid outputs) for quick fixes.  \n",
       "5. **Integration with LangChain**: Seamlessly connects with LangChain code to automatically log and analyze runs.  \n",
       "\n",
       "---\n",
       "\n",
       "**Common Use Cases**  \n",
       "- **Debugging**: Identify and resolve issues in LLM workflows (e.g., hallucinations, data drift).  \n",
       "- **Model Comparison**: Test and compare different models/versions to select the best performer.  \n",
       "- **Cost Management**: Track API usage and costs to optimize resource allocation.  \n",
       "- **Team Collaboration**: Share insights and results across teams for iterative improvements.  \n",
       "\n",
       "---\n",
       "\n",
       "**Summary**  \n",
       "Langsmith is an essential tool for developers building LLM applications with LangChain. It simplifies workflow visualization, performance tracking, and error resolution, enabling teams to iteratively refine and scale their AI solutions effectively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith\", \"business_rules\":\"\"})\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35ba04-196c-42c6-ae5e-cb865671a7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d2a6d70-1288-4b45-9cce-b175cf603d43",
   "metadata": {},
   "source": [
    "👉 **JsonOutputParser** - Generates the output in the JSON fomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0221a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66da8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fe079e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52a5b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple Inc': {'Founded': 'April 1, 1976', 'Founders': ['Steve Jobs', 'Steve Wozniak', 'Ronald Wayne'], 'Headquarters': 'Cupertino, California, USA', 'CEO': 'Tim Cook', 'Products': ['iPhone', 'iPad', 'Mac', 'Apple Watch', 'Apple TV', 'AirPods', 'HomePod', 'Apple Software (iOS, macOS, watchOS, tvOS)'], 'Services': ['Apple Music', 'Apple Pay', 'iCloud', 'Apple Arcade', 'Apple TV+', 'App Store'], 'Revenue (2023)': 'Approx. $394 billion', 'Employees (2023)': 'Approximately 164,000', 'Market Capitalization': 'Over $2 trillion', 'Stock Symbol': 'AAPL'}, 'Microsoft': {'Founded': 'April 4, 1975', 'Founders': ['Bill Gates', 'Paul Allen'], 'Headquarters': 'Redmond, Washington, USA', 'CEO': 'Satya Nadella', 'Products': ['Windows', 'Microsoft Office', 'Surface Devices', 'Xbox Consoles', 'Azure', 'LinkedIn', 'GitHub'], 'Services': ['Microsoft 365', 'Azure Cloud Services', 'Xbox Game Pass', 'LinkedIn Premium', 'Dynamics 365'], 'Revenue (2023)': 'Approx. $211 billion', 'Employees (2023)': 'Approximately 221,000', 'Market Capitalization': 'Over $2 trillion', 'Stock Symbol': 'MSFT'}, 'Comparison': {'Industry': 'Technology', 'Primary Focus': {'Apple Inc': 'Consumer electronics, software, and services', 'Microsoft': 'Software, cloud computing, and hardware'}, 'Global Presence': 'Both companies operate worldwide with extensive global markets.', 'Innovation': {'Apple Inc': 'Known for design-driven innovation in hardware and integrated software ecosystems.', 'Microsoft': 'Leader in software development, cloud infrastructure, and enterprise solutions.'}, 'Financial Health': 'Both companies are among the most valuable publicly traded companies with strong revenue streams and profitability.'}}\n"
     ]
    }
   ],
   "source": [
    "# Create chain\n",
    "\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"query\":\"Compare the Apple Inc and Microsoft\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50822936",
   "metadata": {},
   "source": [
    "👈 **XMLOutputParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ca6e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e83a6cc-7df9-4e85-996e-afe5743f95b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see how the Langchain creates instructions for formatting the output in the XML\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "940f704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, the user asked about Langsmith. I need to explain it in an XML format as per their instructions. Wait, the example shows that even if they mention \"None\" for tags, I have to make the tags myself. Let me think about the structure.\n",
      "\n",
      "First, the user wants information on Langsmith. The key points to cover are what it is, its purpose, features, and maybe use cases. Since XML requires tags, I need to create elements like <name>, <description>, <features>, etc.\n",
      "\n",
      "Wait, the user's initial query was to answer their question using XML with tags made on my own. The example shows that even if tags aren't given, I have to invent them. So I should structure the info into appropriate tags.\n",
      "\n",
      "Start with a root element, maybe <response>. Then inside, perhaps <overview> for the basic info. Under that, <name>, <purpose>, <description>. Then <features> as a list, each feature in a <feature> tag. Maybe a <use_cases> section with examples. Finally, a <conclusion> to summarize.\n",
      "\n",
      "Let me outline it:\n",
      "\n",
      "<response>\n",
      "  <overview>\n",
      "    <name>Langsmith</name>\n",
      "    <purpose>... describe purpose here ...</purpose>\n",
      "    <description>... detailed description ...</description>\n",
      "  </overview>\n",
      "  <features>\n",
      "    <feature>Feature 1</feature>\n",
      "    <feature>Feature 2</feature>\n",
      "    ...\n",
      "  </features>\n",
      "  <use_cases>\n",
      "    <use_case>Use Case 1</use_case>\n",
      "    ...\n",
      "  </use_cases>\n",
      "  <conclusion>... conclusion ...</conclusion>\n",
      "</response>\n",
      "\n",
      "I need to ensure all tags are properly opened and closed, no dangling tags. Also, check that the XML hierarchy makes sense. Let me fill in the content now. Langsmith is an Evaluation as a Service (EaaS) platform by Oobalab. It helps manage large language models, track experiments, etc. Features include experiment tracking, dataset management, model evaluation. Use cases for R&D, production monitoring, etc. Conclusion mentions its benefits.\n",
      "\n",
      "Wait, do I need to mention the company? Probably, yes. Also, make sure each section is well-structured. Let me put it all together, ensuring each tag is properly nested and closed. Avoid any markdown, just XML. Alright, that should work.\n",
      "</think>\n",
      "\n",
      "<response>\n",
      "  <overview>\n",
      "    <name>Langsmith</name>\n",
      "    <purpose>Langsmith is an Evaluation as a Service (EaaS) platform designed to simplify the development, evaluation, and monitoring of large language models (LLMs) and other AI systems.</purpose>\n",
      "    <description>\n",
      "      It provides a unified interface for managing datasets, tracking experiments, and assessing model performance across various metrics. Langsmith is particularly useful for researchers, developers, and teams working on AI projects, as it streamlines workflows and ensures reproducibility.\n",
      "    </description>\n",
      "  </overview>\n",
      "  <key_features>\n",
      "    <feature>Experiment Tracking: Logs and compares model performance across different training runs and configurations.</feature>\n",
      "    <feature>Dataset Management: Stores and organizes training and evaluation datasets for consistent testing.</feature>\n",
      "    <feature>Model Evaluation: Offers pre-built and customizable metrics to assess aspects like accuracy, bias, and coherence.</feature>\n",
      "    <feature>Visualization Tools: Generates interactive dashboards and reports to track model behavior over time.</feature>\n",
      "    <feature>Integration Support: Works with popular frameworks like LangChain, Hugging Face, and custom ML pipelines.</feature>\n",
      "  </key_features>\n",
      "  <use_cases>\n",
      "    <use_case>Research and Development: Iterating on model architectures and hyperparameters.</use_case>\n",
      "    <use_case>Production Monitoring: Detecting performance drift or degradation in deployed models.</use_case>\n",
      "    <use_case>Comparative Analysis: Benchmarking models against each other or industry baselines.</use_case>\n",
      "    <use_case>Collaborative Workflows: Enabling teams to share results and insights in a centralized environment.</use_case>\n",
      "  </use_cases>\n",
      "  <conclusion>\n",
      "    Langsmith serves as an essential tool for organizations aiming to optimize their AI systems, reduce operational overhead, and ensure models meet desired standards across diverse applications.\n",
      "  </conclusion>\n",
      "</response>\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1eec50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, the user is asking what LangChain is. Let me start by recalling what I know. I remember that LangChain is a framework related to large language models. It's used in the development of applications that involve LLMs.\n",
      "\n",
      "Hmm, first, I should define it clearly. LangChain helps developers create applications powered by large language models. It provides tools for integrating these models into applications. Wait, maybe I should mention that it's a framework designed to build applications with LLMs efficiently.\n",
      "\n",
      "I think it's important to highlight its components. There's something about chainable components, like building blocks that can be connected. So, maybe it allows users to chain together different steps in a workflow. For example, processing input, running through an LLM, and then formatting the output.\n",
      "\n",
      "Oh right, modularity is a key point. LangChain offers various modules for different tasks. Like data loading, data transformation, model selection, and output formatting. This modularity makes it flexible for different use cases.\n",
      "\n",
      "Also, it supports multiple LLM providers. So users aren't locked into a single provider like OpenAI or Anthropic. They can switch between different models, which is a big plus.\n",
      "\n",
      "Use cases might include chatbots, data analysis, document processing, and more. It helps in creating custom workflows. Maybe I should give an example, like creating a question-answering system that uses a chain of data retrieval and processing steps.\n",
      "\n",
      "Wait, I should make sure I'm not mixing it up with other frameworks. LangChain is specifically for streamlining LLM workflows. It simplifies tasks like prompt engineering, combining data sources with LLMs, and managing the flow between different processing steps.\n",
      "\n",
      "Let me structure the answer step by step. Start with a concise definition, then break down key features: modularity, chainable components, multi-provider support, and common use cases. Make sure it's clear and easy to understand without too much jargon.\n",
      "</think>\n",
      "\n",
      "<response><answer>LangChain is a framework designed to simplify the development of applications powered by large language models (LLMs). It provides a modular and flexible system for building workflows that integrate LLMs into tasks like data processing, chatbots, and custom applications. Key features include:\n",
      "\n",
      "1. **Modular Components**: Breaks down workflows into reusable, chainable steps (e.g., data input, LLM processing, output formatting).\n",
      "2. **Multi-Model Support**: Works with LLMs from providers like OpenAI, Anthropic, and more, allowing easy switching or combining models.\n",
      "3. **Prompt Engineering Tools**: Helps structure prompts and manage interactions with LLMs efficiently.\n",
      "4. **Data Integration**: Facilitates combining LLMs with external data (e.g., databases, documents) for tasks like Q&A or analysis.\n",
      "5. **Scalability**: Enables building complex, multi-step workflows (e.g., \"chains\" of actions) for real-world applications.\n",
      "\n",
      "It’s widely used for chatbots, data summarization, document analysis, and automating tasks that require LLM-driven logic.</answer></response>\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "chain = prompt | model\n",
    "\n",
    "# Run the chain\n",
    "#response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "raw_output =chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(raw_output.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e95802-9fbd-4788-9510-cd1a23dee75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a3be454-6ebc-4235-812e-3f17ea57fb71",
   "metadata": {},
   "source": [
    "## Enforcing the output formating using Pydantic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab7431f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why did the scarecrow win an award?',\n",
       " 'punchline': 'Because he was outstanding in his field!'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36e1dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': 'Why was the math book sad? Because it had too many problems.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d2969-4337-4b4d-acdd-a44f9cd19038",
   "metadata": {},
   "source": [
    "👈 **YamlOutputParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c90caccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2999f98",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
